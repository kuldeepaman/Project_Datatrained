{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "\"\"\"\n", "Created on Tue Feb 28"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@author: Kuldeep Kumar\n", "\"\"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import warnings"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from matplotlib import pyplot"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["warnings.filterwarnings(\"ignore\")\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import pandas as pd\n", "from sklearn import preprocessing\n", "from sklearn.compose import ColumnTransformer\n", "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.metrics import accuracy_score,jaccard_score,f1_score,log_loss,confusion_matrix\n", "from sklearn.metrics import confusion_matrix,classification_report\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.svm import SVC\n", "from sklearn.linear_model import LogisticRegression\n", "from pandas.plotting import scatter_matrix\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.model_selection import KFold\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.metrics import classification_report\n", "from sklearn.metrics import confusion_matrix\n", "from sklearn.metrics import accuracy_score\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.svm import SVC\n", "from sklearn.linear_model import Lasso\n", "from sklearn.linear_model import ElasticNet\n", "from sklearn.ensemble import AdaBoostClassifier\n", "from sklearn.ensemble import GradientBoostingClassifier\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.ensemble import ExtraTreesClassifier"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["hr_df = pd.read_csv(\"WA_Fn-UseC_-HR-Employee-Attrition.csv\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Look up in the data\",hr_df.head())\n", "print(\"Describe the Data\",hr_df.describe())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Shape of Data\",hr_df.shape)\n", "print(\"\\n Null Valve in dataset \", hr_df.isnull().sum())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["class distribution"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(hr_df.groupby('Attrition').size())\n", "# Transform into binary classification\n", "hr_df['Attrition'] = [1 if b == 'Yes' else 0 for b in hr_df.Attrition]\n", "print(\"After classification Attrition distribution\",hr_df.groupby('Attrition').size())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Convert Categorical variable into onehotencoder/dummy variables"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["hr_df['BusinessTravel'] = pd.get_dummies(hr_df['BusinessTravel'])\n", "hr_df['Department'] = pd.get_dummies(hr_df['Department'])\n", "hr_df['EducationField'] = pd.get_dummies(hr_df['EducationField'])\n", "hr_df['Gender'] = pd.get_dummies(hr_df['Gender'])\n", "hr_df['JobRole'] = pd.get_dummies(hr_df['JobRole'])\n", "hr_df['MaritalStatus'] = pd.get_dummies(hr_df['MaritalStatus'])\n", "hr_df['OverTime'] = pd.get_dummies(hr_df['OverTime'])\n", "hr_df['Over18'] = pd.get_dummies(hr_df['Over18'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["hr_df.to_csv(\"Afterencoding.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split of Data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Y=hr_df.iloc[:,1]\n", "X=hr_df.drop(['Attrition'],axis = 1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["aking as nd Array"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dataframe=X.values\n", "X=dataframe[:,:]\n", "Y=Y.values"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(X)\n", "print(Y)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["validation_size = 0.30\n", "seed = 7\n", "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size, random_state=seed)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["est options and evaluation metric"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["num_folds = 10\n", "seed = 7\n", "scoring = 'accuracy'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["pot-Check Algorithms"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["models = []\n", "models.append(('LR', LogisticRegression()))\n", "models.append(('LDA', LinearDiscriminantAnalysis()))\n", "models.append(('KNN', KNeighborsClassifier()))\n", "models.append(('CART', DecisionTreeClassifier()))\n", "models.append(('NB', GaussianNB()))\n", "models.append(('SVM', SVC()))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["evaluate each model in turn"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results = []\n", "names = []\n", "for name, model in models:\n", "    kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n", "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n", "    results.append(cv_results)\n", "    names.append(name)\n", "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n", "    print(msg)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compare Algorithms"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = pyplot.figure()\n", "fig.suptitle('Algorithm Comparison')\n", "ax = fig.add_subplot(111)\n", "pyplot.boxplot(results)\n", "ax.set_xticklabels(names)\n", "pyplot.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Standardize the dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pipelines = []\n", "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR',LogisticRegression())])))\n", "pipelines.append(('ScaledLDA', Pipeline([('Scaler', StandardScaler()),('LDA',LinearDiscriminantAnalysis())])))\n", "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN',KNeighborsClassifier())])))\n", "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART',DecisionTreeClassifier())])))\n", "pipelines.append(('ScaledNB', Pipeline([('Scaler', StandardScaler()),('NB',GaussianNB())])))\n", "pipelines.append(('ScaledSVM', Pipeline([('Scaler', StandardScaler()),('SVM', SVC())])))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results = []\n", "names = []\n", "for name, model in pipelines:\n", "    kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n", "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n", "    results.append(cv_results)\n", "    names.append(name)\n", "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n", "    print(msg)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compare Algorithms"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = pyplot.figure()\n", "fig.suptitle('Scaled Algorithm Comparison')\n", "ax = fig.add_subplot(111)\n", "pyplot.boxplot(results)\n", "ax.set_xticklabels(names)\n", "pyplot.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scaler = StandardScaler().fit(X_train)\n", "rescaledX = scaler.transform(X_train)\n", "#k_values = np.array([0.05,0.1,0.2,0.3,0.4])\n", "# Create regularization penalty space\n", "penalty = ['l1', 'l2']\n", "# Create regularization hyperparameter spac\n", "C = np.logspace(0,4,10)\n", "# Create hyperparameter options\n", "hyperparameters = dict(C=C, penalty=penalty)\n", "model = LogisticRegression()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create grid search using 5-fold cross validation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["grid = GridSearchCV(model, hyperparameters, cv=5, verbose=0)\n", "grid_result = grid.fit(rescaledX, Y_train)\n", "y_pred = grid_result.predict(X_validation)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n", "means = grid_result.cv_results_['mean_test_score']\n", "stds = grid_result.cv_results_['std_test_score']\n", "params = grid_result.cv_results_['params']\n", "for mean, stdev, param in zip(means, stds, params):\n", "    print(\"mean, Standard Deviation and params %f (%f) with: %r\" % (mean, stdev, param))\n", "print(\"Accuracy {0:.2f}%\".format(100*accuracy_score(y_pred, Y_validation)))\n", "print(confusion_matrix(Y_validation, y_pred))\n", "print(classification_report(Y_validation, y_pred))\n", "#Output after tunning is\n", "#Best: 0.869780 using {'C': 1.0, 'penalty': 'l2'}\n", "#mean, Standard Deviation and params nan (nan) with: {'C': 1.0, 'penalty': 'l1'}\n", "#mean, Standard Deviation and params 0.869780 (0.003507) with: {'C': 1.0, 'penalty': 'l2'}\n", "#mean, Standard Deviation and params nan (nan) with: {'C': 2.7825594022071245, 'penalty': 'l1'}\n", "#mean, Standard Deviation and params 0.866862 (0.006552) with: {'C': 2.7825594022071245, 'penalty': 'l2'}\n", "#mean, Standard Deviation and params nan (nan) with: {'C': 7.742636826811269, 'penalty': 'l1'}\n", "#mean, Standard Deviation and params 0.866862 (0.006552) with: {'C': 7.742636826811269, 'penalty': 'l2'}\n", "#mean, Standard Deviation and params nan (nan) with: {'C': 21.544346900318832, 'penalty': 'l1'}\n", "#mean, Standard Deviation and params 0.866862 (0.008980) with: {'C': 21.544346900318832, 'penalty': 'l2'}\n", "#mean, Standard Deviation and params nan (nan) with: {'C': 59.94842503189409, 'penalty': 'l1'}\n", "#mean, Standard Deviation and params 0.866862 (0.008980) with: {'C': 59.94842503189409, 'penalty': 'l2'}\n", "#mean, Standard Deviation and params nan (nan) with: {'C': 166.81005372000593, 'penalty': 'l1'}\n", "#mean, Standard Deviation and params 0.866862 (0.008980) with: {'C': 166.81005372000593, 'penalty': 'l2'}\n", "#mean, Standard Deviation and params nan (nan) with: {'C': 464.15888336127773, 'penalty': 'l1'}\n", "#mean, Standard Deviation and params 0.866862 (0.008980) with: {'C': 464.15888336127773, 'penalty': 'l2'}\n", "#mean, Standard Deviation and params nan (nan) with: {'C': 1291.5496650148827, 'penalty': 'l1'}\n", "#mean, Standard Deviation and params 0.866862 (0.008980) with: {'C': 1291.5496650148827, 'penalty': 'l2'}\n", "#mean, Standard Deviation and params nan (nan) with: {'C': 3593.813663804626, 'penalty': 'l1'}\n", "#mean, Standard Deviation and params 0.866862 (0.008980) with: {'C': 3593.813663804626, 'penalty': 'l2'}\n", "#mean, Standard Deviation and params nan (nan) with: {'C': 10000.0, 'penalty': 'l1'}\n", "#mean, Standard Deviation and params 0.866862 (0.008980) with: {'C': 10000.0, 'penalty': 'l2'}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["utput of confusion Matrix"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ccuracy 84.13%<br>\n", "[371   0]<br>\n", "[ 70   0]]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [" #             precision    recall  f1-score   support\n", "#\n", "#           0       0.84      1.00      0.91       371\n", "#           1       0.00      0.00      0.00        70"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  accuracy                           0.84       441<br>\n", "  macro avg       0.42      0.50      0.46       441<br>\n", "weighted avg       0.71      0.84      0.77       441"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}