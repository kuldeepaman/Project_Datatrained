{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "import warnings\n", "warnings.filterwarnings(\"ignore\")\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import re\n", "from matplotlib import pyplot\n", "from xgboost import XGBRegressor\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.decomposition import TruncatedSVD\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.model_selection import KFold\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.linear_model import LinearRegression\n", "from sklearn.linear_model import Lasso\n", "from sklearn.linear_model import ElasticNet\n", "from sklearn.tree import DecisionTreeRegressor\n", "from sklearn.neighbors import KNeighborsRegressor\n", "from sklearn.svm import SVR\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.ensemble import RandomForestRegressor\n", "from sklearn.ensemble import GradientBoostingRegressor\n", "from sklearn.ensemble import ExtraTreesRegressor\n", "from sklearn.ensemble import AdaBoostRegressor\n", "from sklearn.metrics import mean_squared_error"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_df = pd.read_excel('Final_Train.xlsx')\n", "test_df = pd.read_excel('Final_Test.xlsx')\n", "sub_df = pd.read_excel('Sample_submission.xlsx')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Lookup on train data\",train_df.head())\n", "print(\"Shape of train data\",train_df.shape)\n", "print(\"Null value in train data set\", train_df.isnull().sum())\n", "print(\"Lookup into test data\",test_df.head())\n", "print(\"Sum of Null value in test \",test_df.isnull().sum())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Extract String from exp"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_df['Experience'] = train_df['Experience'].str[0:-17].astype(int)\n", "test_df['Experience'] = test_df['Experience'].str[0:-17].astype(int)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["xtarct Rating string"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_df['Rating'] = train_df['Rating'].str[0:-1].astype(float)\n", "test_df['Rating'] = test_df['Rating'].str[0:-1].astype(float)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ill the null value in place"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_df['Place'].fillna('none, none', inplace=True)\n", "test_df['Place'].fillna('none, none', inplace=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Extract the Area and City from place"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_df['Area'] = train_df['Place'].str.rsplit(',', 1).str.get(0)\n", "train_df['City'] = train_df['Place'].str.rsplit(',', 1).str.get(1)\n", "test_df['Area'] = test_df['Place'].str.rsplit(',', 1).str.get(0)\n", "test_df['City'] = test_df['Place'].str.split(',', 1).str.get(1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_df['City'] = train_df['City'].str.strip()\n", "test_df['City'] = test_df['City'].str.strip()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Lookup data after extraction\",train_df.head())\n", "print(\"Unique value for city After Extraction\",train_df['City'].unique())\n", "print(\"Unique value for city After Extraction\",test_df['City'].unique())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Null vaule\",train_df[train_df['City'].isnull()])\n", "train_df.loc[train_df['City'].isnull(), 'Area'] = 'none'\n", "train_df['City'] = train_df['City'].fillna('none')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_df['City'].unique()\n", "train_df['Area'].nunique()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_df['Profile'].unique()\n", "test_df['Profile'].unique()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["bitwise operator to check Misc info present or not 1 or 0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_df['Has_M_Info'] = (~train_df['Miscellaneous_Info'].isnull())\n", "test_df['Has_M_Info'] = (~test_df['Miscellaneous_Info'].isnull())\n", "train_df['Has_M_Info'] = train_df['Has_M_Info'].astype(int)\n", "test_df['Has_M_Info'] = test_df['Has_M_Info'].astype(int)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Look up after Misc info\",train_df.head())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["quals = pd.DataFrame(item for item in train_df['Qualification'].str.split(', '))\n", "print(\"Qualification is\",quals.head())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Null for Qualification\",quals.isnull().sum())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(10):\n", "    print(quals[i].nunique())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"value count for Qualifivation\", quals[0].value_counts())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vecz = TfidfVectorizer(analyzer='word')\n", "vecz.fit(train_df['Qualification'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["qual_train = vecz.transform(train_df['Qualification'])\n", "qual_test = vecz.transform(test_df['Qualification'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ingular Value Decomposition (SVD) is a matrix factorization technique that<br>\n", "factors a matrix M into the three matrices U, \u00ce\u00a3, and V. This is very similar to PCA,<br>\n", "excepting that the factorization for SVD is done on the data matrix, whereas for PCA,<br>\n", "the factorization is done on the covariance matrix. Typically, SVD is used under the hood to<br>\n", "find the principle components of a matrix."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["svd = TruncatedSVD(n_components=20)\n", "svd.fit(qual_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Variance sum \",svd.explained_variance_ratio_.sum())\n", "print(\"Variance ratio\",svd.explained_variance_ratio_)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["qual_train = svd.transform(qual_train)\n", "qual_train = pd.DataFrame(qual_train, columns=['svd_{}'.format(i) for i in range(20)])\n", "train_df = pd.concat((train_df, qual_train), axis=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["qual_test = svd.transform(qual_test)\n", "qual_test = pd.DataFrame(qual_test, columns=['svd_{}'.format(i) for i in range(20)])\n", "test_df = pd.concat((test_df, qual_test), axis=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_df.to_csv(\"train.csv\")\n", "test_df.to_csv(\"test.csv\")\n", "Y=train_df[\"Fees\"].values\n", "X=train_df.drop(['Fees'],axis=1)\n", "array = X.values\n", "X = array[:,8:30]\n", "#Y = array[:,6]\n", "validation_size = 0.20\n", "seed = 7\n", "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y,test_size=validation_size, random_state=seed)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Test options and evaluation metric"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["num_folds = 10\n", "seed = 7\n", "scoring = 'neg_mean_squared_error'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["pot-Check Algorithms"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["models = []\n", "models.append(('LR', LinearRegression()))\n", "models.append(('XGB', XGBRegressor()))\n", "models.append(('LASSO', Lasso()))\n", "models.append(('EN', ElasticNet()))\n", "models.append(('KNN', KNeighborsRegressor()))\n", "models.append(('CART', DecisionTreeRegressor()))\n", "models.append(('SVR', SVR()))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["evaluate each model in turn"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results = []\n", "names = []\n", "for name, model in models:\n", "    kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n", "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n", "    results.append(cv_results)\n", "    names.append(name)\n", "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n", "    print(msg)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["owest negtive MSE is for LR followed by LASSO"]}, {"cell_type": "markdown", "metadata": {}, "source": ["R: -31072.127725 (1852.614533)<br>\n", "GB: -32960.497059 (2147.411868)<br>\n", "ASSO: -31285.753686 (1870.626560)<br>\n", "N: -35096.030674 (1803.986785)<br>\n", "NN: -35964.710138 (3502.354681)<br>\n", "ART: -39118.208803 (4076.907318)<br>\n", "VR: -33103.136033 (2038.209706)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ompare Algorithms"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = pyplot.figure()\n", "fig.suptitle('Algorithm Comparison')\n", "ax = fig.add_subplot(111)\n", "pyplot.boxplot(results)\n", "ax.set_xticklabels(names)\n", "pyplot.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["valuate Algorithms: Standardization"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Standardize the dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pipelines = []\n", "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR',LinearRegression())])))\n", "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('XGB',XGBRegressor())])))\n", "pipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()),('LASSO', Lasso())])))\n", "pipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()),('EN', ElasticNet())])))\n", "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsRegressor())])))\n", "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeRegressor())])))\n", "pipelines.append(('ScaledSVR', Pipeline([('Scaler', StandardScaler()),('SVR', SVR())])))\n", "results = []\n", "names = []\n", "for name, model in pipelines:\n", "    kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n", "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n", "    results.append(cv_results)\n", "    names.append(name)\n", "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n", "    print(msg)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["After Scaling below output gives lowest MSE for LR, LASSO and EN<br>\n", "caledLR: -31073.285058 (1852.428878)<br>\n", "caledLR: -33000.053603 (2380.501922)<br>\n", "caledLASSO: -31057.987851 (1826.336022)<br>\n", "caledEN: -31605.583914 (1711.448216)<br>\n", "caledKNN: -35694.351220 (2920.487089)<br>\n", "caledCART: -38696.891647 (4262.623551)<br>\n", "caledSVR: -34017.125788 (2013.529279)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compare Algorithms"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = pyplot.figure()\n", "fig.suptitle('Scaled Algorithm Comparison')\n", "ax = fig.add_subplot(111)\n", "pyplot.boxplot(results)\n", "ax.set_xticklabels(names)\n", "pyplot.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Algorithm tuning"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scaler = StandardScaler().fit(X_train)\n", "rescaledX = scaler.transform(X_train)\n", "k_values = np.array([1,0.1,0.01,0.001,0.0001,0])\n", "param_grid = dict(alpha=k_values)\n", "model = Lasso()\n", "kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n", "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n", "grid_result = grid.fit(rescaledX, Y_train)\n", "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n", "print(\"Best Estimator\",grid.best_estimator_.alpha)\n", "means = grid_result.cv_results_['mean_test_score']\n", "stds = grid_result.cv_results_['std_test_score']\n", "params = grid_result.cv_results_['params']\n", "for mean, stdev, param in zip(means, stds, params):\n", "    print(\"mean, Standard Deviation and params %f (%f) with: %r\" % (mean, stdev, param))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["valuate four different ensemble machine learning<br>\n", "lgorithms, two boosting and two bagging methods:<br>\n", " Boosting Methods: AdaBoost (AB) and Gradient Boosting (GBM).<br>\n", " Bagging Methods: Random Forests (RF) and Extra Trees (ET)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["ensembles"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ensembles = []\n", "ensembles.append(('ScaledAB', Pipeline([('Scaler', StandardScaler()),('AB',AdaBoostRegressor())])))\n", "ensembles.append(('ScaledGBM', Pipeline([('Scaler', StandardScaler()),('GBM', GradientBoostingRegressor())])))\n", "ensembles.append(('ScaledRF', Pipeline([('Scaler', StandardScaler()),('RF', RandomForestRegressor())])))\n", "ensembles.append(('ScaledET', Pipeline([('Scaler', StandardScaler()),('ET', ExtraTreesRegressor())])))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results = []\n", "names = []\n", "for name, model in ensembles:\n", "    kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n", "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n", "    results.append(cv_results)\n", "    names.append(name)\n", "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n", "    print(msg)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Output is best for GBM<br>\n", "caledAB: -32203.544297 (2290.880793)<br>\n", "caledGBM: -30424.137942 (2154.809940)<br>\n", "caledRF: -31673.784577 (2543.114782)<br>\n", "caledET: -32788.928779 (2697.184527)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compare Algorithms"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = pyplot.figure()\n", "fig.suptitle('Scaled Ensemble Algorithm Comparison')\n", "ax = fig.add_subplot(111)\n", "pyplot.boxplot(results)\n", "ax.set_xticklabels(names)\n", "pyplot.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Tune Ensemble Methods<br>\n", "GBM<br>\n", "Tune scaled GBM"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scaler = StandardScaler().fit(X_train)\n", "rescaledX = scaler.transform(X_train)\n", "param_grid = dict(n_estimators=np.array([50,100,150,200,250,300,350,400]))\n", "model = GradientBoostingRegressor(random_state=seed)\n", "kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n", "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n", "grid_result = grid.fit(rescaledX, Y_train)\n", "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n", "means = grid_result.cv_results_['mean_test_score']\n", "stds = grid_result.cv_results_['std_test_score']\n", "params = grid_result.cv_results_['params']\n", "for mean, stdev, param in zip(means, stds, params):\n", "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["##Finalize the Model<br>\n", " prepare the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scaler = StandardScaler().fit(X_train)\n", "rescaledX = scaler.transform(X_train)\n", "model = GradientBoostingRegressor(random_state=seed, n_estimators=400)\n", "model.fit(rescaledX, Y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["transform the validation dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rescaledValidationX = scaler.transform(X_validation)\n", "predictions = model.predict(rescaledValidationX)\n", "print(mean_squared_error(Y_validation, predictions))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["n final test data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["final_df=test_df.values\n", "Y_final=final_df[:,8:29]\n", "final_prediction=model.predict(Y_final)\n", "print(final_prediction)\n", "final_prediction_res=pd.DataFrame(final_prediction,columns=['Fees']).round(decimals=0)\n", "final_prediction_res.to_excel(\"Final_Submission.xlsx\",index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}